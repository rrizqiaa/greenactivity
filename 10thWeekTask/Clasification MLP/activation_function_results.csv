Activation_Function,Final_Train_Loss,Final_Test_Accuracy
linear,0.5775988012552261,0.728125
sigmoid,0.4420494243502617,0.753125
relu,0.3396368339657784,0.753125
softmax,0.39685427471995355,0.753125
tanh,0.17428412064909934,0.7625
