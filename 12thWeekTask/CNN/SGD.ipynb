{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# Check if CUDA is available\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"CUDA is not available. Please ensure a GPU is available and CUDA is properly installed.\")\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# Load dataset (CIFAR-10 as an example)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Define CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, kernel_size, pooling_type=\"max\"):\n",
    "        super(CNN, self).__init__()\n",
    "        if pooling_type == \"max\":\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "        elif pooling_type == \"avg\":\n",
    "            self.pool = nn.AvgPool2d(2, 2)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=kernel_size, padding=kernel_size // 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=kernel_size, padding=kernel_size // 2)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.ReLU()(self.conv1(x)))\n",
    "        x = self.pool(nn.ReLU()(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Training function\n",
    "def train_model(model, optimizer, scheduler, epochs=10, early_stopping_patience=5):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for inputs, labels in DataLoader(train_dataset, batch_size=64, shuffle=True):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "# Hyperparameter configurations\n",
    "kernel_sizes = [3, 5, 7]\n",
    "pooling_types = [\"max\", \"avg\"]\n",
    "epochs_options = [5, 50, 100]\n",
    "\n",
    "# Experiment for SGD\n",
    "for kernel_size in kernel_sizes:\n",
    "    for pooling in pooling_types:\n",
    "        for epochs in epochs_options:\n",
    "            model = CNN(kernel_size=kernel_size, pooling_type=pooling).to(device)\n",
    "            optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "            scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "            print(f\"Training with Kernel Size: {kernel_size}, Pooling: {pooling}, Epochs: {epochs}\")\n",
    "            train_model(model, optimizer, scheduler, epochs)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
